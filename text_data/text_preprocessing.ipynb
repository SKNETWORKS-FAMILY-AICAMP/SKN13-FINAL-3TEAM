{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b7e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hyundai_docs_parse.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile hyundai_docs_parse.py\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from pypdf import PdfReader\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "# 1. 하이픈 기준 청크 분할\n",
    "def split_by_hyphen(text, delim=\"----------------------------------------\"):\n",
    "    return [c.strip() for c in text.split(delim) if c.strip()]\n",
    "\n",
    "def split_by_topic(text):\n",
    "    splitters = [\"요 약\", \"서 론\", \"실험 설정\", \"실험 및 결과\", \"1. 차체 측면 형태에 따른 공력 성능 비교\", \"2. 차체 측면 유리창 각도에 따른 공력 성능 비교\", \"3. 엔진 후드의 각도 변화에 따른 공력 성능 비교\",\\\n",
    "                \"4. 차체의 루프(roof) 각도에 따른 공력 성능 비교\", \"4. 후방 디퓨저 적용에 따른 공력 성능 변화\", \"결 론\",\\\n",
    "                \"2.1 플루이딕 스컬프쳐와 스톰 엣지\", \"2.2 센슈어스 스포트니스\", \"3.1 플루이득 스컬프쳐와 스톰엣지 미의식\",\\\n",
    "                \"3.2 센슈어스 스포트니스 미의식\", \"4.1 인지된 미의식과 인식적 환원의 차이\", \"4.2 플루이딕 스컬프쳐와 스톰 엣지의 신경학적 해석\",\\\n",
    "                \"4.3 센슈어스 스포트니스의 신경학적 해석\", \"4.3.1 파라메트릭 다이나믹스\", \"4.3.2 파라메트릭 주얼\", \"4.3.3. 히든라이팅\",\\\n",
    "                \"4.3.4 현대자동차 디자인 철학의 신경학적 해석\" \"REFLECTIONS IN MOTION\", \"HERITAGE SERIES\", \"PONY\", \"COLOR & LIGHT\",\\\n",
    "                \"MATERIAL\", \"A JOURNEY\"]\n",
    "\n",
    "    # splitter 기준으로 인덱스 찾기\n",
    "    indices = []\n",
    "    for splitter in splitters:\n",
    "        for match in re.finditer(re.escape(splitter), text):\n",
    "            indices.append((match.start(), splitter))\n",
    "    indices.sort()  # 등장 순 정렬\n",
    "\n",
    "    sections = []\n",
    "    for i, (start_idx, splitter) in enumerate(indices):\n",
    "        end_idx = indices[i+1][0] if i+1 < len(indices) else len(text)\n",
    "        content = text[start_idx:end_idx].strip()\n",
    "        sections.append(content)\n",
    "\n",
    "    return sections\n",
    "\n",
    "# 2. 충실한 답변 생성용 프롬프트\n",
    "def make_prompt(article_chunk):\n",
    "    prompt = f\"\"\"\n",
    "너는 자동차 기사로부터 학습용 QA(질문-답변) 데이터셋을 만드는 어시스턴트야.\n",
    "아래 기사 내용을 바탕으로, 정보가 겹치지 않는 다양한 질문-답변 쌍을 가능한 많이 생성해줘.\n",
    "각 질문은 한글로, 답변도 한글로 반드시 기사에 근거해서 작성하되,\n",
    "답변이 가능한 한 충실하고 자세하게(2문장 이상, 핵심+배경+수치/예시 등 포함) 만들어줘.\n",
    "\n",
    "\n",
    "출력 형식:\n",
    "Q: (질문)\n",
    "A: (답변)\n",
    "\n",
    "기사:\n",
    "{article_chunk}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 3. ChatCompletion(v1.x) 함수\n",
    "def extract_qa_from_chunk(chunk, model_name=\"gpt-4o\", max_tokens=2048, temperature=0.3, retries=3):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": make_prompt(chunk)}],\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"[오류] 재시도 {i+1}: {e}\")\n",
    "            time.sleep(2)\n",
    "    return \"[에러] 추출 실패!\"\n",
    "\n",
    "# 4. QA 텍스트를 messages 배열로 변환\n",
    "def qa_text_to_messages(qa_text):\n",
    "    messages = []\n",
    "    lines = [line.strip() for line in qa_text.split('\\n') if line.strip()]\n",
    "    last_q = None\n",
    "    for line in lines:\n",
    "        if line.startswith(\"Q:\"):\n",
    "            last_q = line[2:].strip()\n",
    "            messages.append({\"role\": \"user\", \"content\": last_q})\n",
    "        elif line.startswith(\"A:\") and last_q is not None:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": line[2:].strip()})\n",
    "    return messages\n",
    "\n",
    "# 5. PDF 텍스트 추출\n",
    "def extract_pdf_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        # 각 페이지에서 텍스트 추출\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            full_text += text + \"\\n\"\n",
    "    return full_text\n",
    "\n",
    "# 6. 메인 파이프라인\n",
    "def main(file_name):\n",
    "    with open(f\"./finetuning/{file_name}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    print(f\"총 {len(text)}자 텍스트 로드 완료\")\n",
    "\n",
    "    # 하이픈 기준 청크\n",
    "    chunks = split_by_hyphen(text)\n",
    "    print(f\"총 {len(chunks)}개 chunk로 분할됨!\")\n",
    "\n",
    "    # 반복 QA 추출 및 json 저장\n",
    "    with open(f\"./QA_context/{file_name}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        cnt = 0\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            print(f\"[{idx+1}/{len(chunks)}] QA 추출 중...\")\n",
    "            qa_text = extract_qa_from_chunk(chunk, model_name=model_name)\n",
    "            messages = qa_text_to_messages(qa_text)\n",
    "            context = chunk\n",
    "            if messages:\n",
    "                json_obj = {\"messages\": messages}\n",
    "                json_obj2 = {\"context\": context}\n",
    "                json_merged = {**json_obj, **json_obj2}\n",
    "                cnt += len(json_obj[\"messages\"])\n",
    "                f.write(json.dumps(json_merged, ensure_ascii=False) + \"\\n\")\n",
    "            time.sleep(1.1)  # API 부하 방지\n",
    "\n",
    "    print(f\"✅ 전체 QA_context {len(chunks)}개 context, 세부 데이터 {cnt}개 저장 완료 → {file_name}.json\")\n",
    "\n",
    "# 7. pdf 용 메인 파이프라인\n",
    "def main2(file_name):\n",
    "    # PDF 텍스트 추출\n",
    "    text = extract_pdf_text(f\"./finetuning/{file_name}.txt\")\n",
    "    print(f\"총 {len(text)}자 텍스트 로드 완료\")\n",
    "\n",
    "    # 세부 내용 기준 기준 청크\n",
    "    chunks = split_by_topic(text)\n",
    "    print(f\"총 {len(chunks)}개 chunk로 분할됨!\")\n",
    "\n",
    "    # 반복 QA 추출 및 json 저장\n",
    "    with open(f\"./QA_context/{file_name}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        cnt = 0\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            print(f\"[{idx+1}/{len(chunks)}] QA 추출 중...\")\n",
    "            qa_text = extract_qa_from_chunk(chunk, model_name=model_name)\n",
    "            messages = qa_text_to_messages(qa_text)\n",
    "            context = chunk\n",
    "            if messages:\n",
    "                json_obj = {\"messages\": messages}\n",
    "                json_obj2 = {\"context\": context}\n",
    "                json_merged = {**json_obj, **json_obj2}\n",
    "                cnt += len(json_obj[\"messages\"])\n",
    "                f.write(json.dumps(json_merged, ensure_ascii=False) + \"\\n\")\n",
    "            time.sleep(1.1)  # API 부하 방지\n",
    "\n",
    "    print(f\"✅ 전체 QA_context {len(chunks)}개 context, 세부 데이터 {cnt}개 저장 완료 → {file_name}.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_names = [\"현대 디자인 모토\", \"hyundai_journal_articles\", \"interview_articles\", \"new_articles\", \"preview_articles\", \"total_articles\"]\n",
    "    file_names2 = [\"자동차 차체 형태 디자인이 공기역학 성능에 미치는영향에 대한 연구\", \"현대 모터스튜디오_디자인 관련 문서\", \"현대자동차 디자인 철학에 내재하는 미의식의 신경학적 해석\"]\n",
    "    # for file in file_names:\n",
    "    #     main(f\"{file}\")\n",
    "    for file in file_names2:\n",
    "        main2(f\"{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e94395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'user', 'content': '현대자동차의 디자인 철학은 무엇인가요?'}, {'role': 'assistant', 'content': \"현대자동차의 디자인 철학은 '센슈어스 스포티니스'입니다. 이 철학은 각 차량의 독창성을 존중하면서도 심미적으로 자연스럽고 균형 잡힌 디자인을 구현하는 것을 목표로 합니다.\"}, {'role': 'user', 'content': '현대자동차의 디자인 정신은 무엇에 기반하고 있나요?'}, {'role': 'assistant', 'content': \"현대자동차의 디자인 정신은 '플루이딕 스컬프처(Fluidic Sculpture)'에 기반하고 있습니다. 이는 자연을 모티브로 하여 예술적인 방식으로 완성된 디자인으로, 살아있는 듯한 아름다움과 현대적이고 예술적인 조형을 추구합니다.\"}, {'role': 'user', 'content': '현대자동차의 외장 디자인 특징은 무엇인가요?'}, {'role': 'assistant', 'content': '현대자동차의 외장 디자인은 감각적이고 스포티한 스타일을 특징으로 합니다. 와이드한 프론트 후드와 파라메트릭 쥬얼을 캐스캐이딩 그릴에 일체화하여 보석과 같은 감성을 구현하며, 측면부의 깔끔하게 이어지는 캐릭터 라인과 함께 풍부하고 세련된 볼륨감을 표현합니다.'}, {'role': 'user', 'content': '현대자동차의 인테리어 디자인은 어떤 소재를 사용하나요?'}, {'role': 'assistant', 'content': '현대자동차의 인테리어 디자인은 패브릭 신소재와 리얼 우드 등 다양한 소재를 사용하여 감성적이고 편안한 느낌을 전달합니다. 이러한 소재들은 사용자에게 고급스러우면서도 따뜻한 분위기를 제공합니다.'}, {'role': 'user', 'content': '현대자동차의 사용자 중심 디자인은 어떤 특징을 가지고 있나요?'}, {'role': 'assistant', 'content': '현대자동차의 사용자 중심 디자인은 운전자의 직관적인 차량 조작을 돕기 위해 21.5인치 크기의 파노라믹 플로팅 디스플레이를 포함하고 있습니다. 또한, 비행기의 환기 시스템에서 영감을 받은 2-way 에어 벤틸레이션 시스템을 통해 차량을 항상 쾌적한 상태로 유지합니다.'}, {'role': 'user', 'content': '현대자동차의 전기차 디자인에서 중요한 비율 요소는 무엇인가요?'}, {'role': 'assistant', 'content': '현대자동차의 전기차 디자인에서 중요한 비율 요소는 롱 휠 베이스, 큰 휠, 그리고 짧은 오버행입니다. 이러한 비율은 진보적인 전기차를 구현하기 위한 최상의 비율로, 현대자동차의 디자인 철학을 반영하여 차량의 독창성과 기능성을 동시에 강조합니다.'}], 'context': '브랜드스토리 > Design | 현대자동차 - 현대닷컴 | 대한민국 대표 자동차회사 hyundai.com\\n단순히 멋지고 아름다운 자동차가 아니라, 고객의 개성과 취향을 존중하는 디자인으로,\\n고객 기대를 뛰어넘는 디자인 이상의 가치를 실현해 나갈 것입니다.\\n\\n이를 위해 현대자동차는 ‘센슈어스 스포티니스‘라는 동일한 디자인 철학 아래,\\n각 차량의 독창성 역시 존중하는 디자인 방식을 추구해 나갈 계획입니다.\\n심미적으로도 자연스러우며, 균형 잡힌 디자인을 구현했습니다.\\n롱 휠 베이스와 큰 휠, 그리고 짧은 오버행으로 진보적인 전기차를 구현하기 위한 최상의 비율을 완성시켰습니다.\\n현대자동차의 창조의 바탕에는 현대자동차만의 디자인 정신, 플루이딕 스컬프처(Fluidic Sculpture)’가 있습니다. 플루이딕 스컬프처는 자연을 모티브로 한 디자인을 가장 예술적인 방식으로 완성합니다. 살아있는 듯한 아름다움이 담긴 현대적이고 예술적인 조형. 예술혼과 정성을 다하여 빚은 디자인을 우리는 플루이딕 스컬프처라 부릅니다.\\n하나의 선으로 완성된 것처럼 이음새 없이 이어지는 실루엣에는 간결한 구조를 뜻하는 ‘라이트 아키텍쳐’ 스타일이 적용됐습니다.\\n외장의 감각적이고 스포티한 스타일은 내장 디자인으로 스며들어 차량 안팎에서 동일한 감성을 느낄 수 있습니다.\\n전면부의 와이드한 프론트 후드는 차량의 존재감을 부각시키며, 파라메트릭 쥬얼을 캐스캐이딩 그릴에 일체화하여 보석과도 같은 감성을 구현하며 측면부의 깔끔하게 이어지는 캐릭터 라인과 함께 전체적으로 표현되는 풍부하고 세련된 볼륨감을 통해 감각적이고 스포티한 디자인을 구현했습니다.\\n현대자동차 디자이너들에게 있어 핵심적인 디자인 원칙은 기능성을 온전히 경험할 수 있는 디자인을 한다는 것입니다.\\n운전자의 직관적인 차량 조작을 돕는 21.5인치 크기의 파노라믹 플로팅 디스플레이 등 편의성을 높인 사용자 중심의 디자인이 적용됐습니다.\\n패브릭 신소재, 리얼 우드 등 다양한 소재를 사용한 인테리어로 감성적이고 편안한 느낌을 전달하며 비행기의 환기시스템에서 영감을 받은 2-way 에어 벤틸레이션 시스템은 차량을 항상 쾌적한 상태로 유지합니다.'}\n",
      "주어진 Context : \n",
      " 브랜드스토리 > Design | 현대자동차 - 현대닷컴 | 대한민국 대표 자동차회사 hyundai.com\n",
      "단순히 멋지고 아름다운 자동차가 아니라, 고객의 개성과 취향을 존중하는 디자인으로,\n",
      "고객 기대를 뛰어넘는 디자인 이상의 가치를 실현해 나갈 것입니다.\n",
      "\n",
      "이를 위해 현대자동차는 ‘센슈어스 스포티니스‘라는 동일한 디자인 철학 아래,\n",
      "각 차량의 독창성 역시 존중하는 디자인 방식을 추구해 나갈 계획입니다.\n",
      "심미적으로도 자연스러우며, 균형 잡힌 디자인을 구현했습니다.\n",
      "롱 휠 베이스와 큰 휠, 그리고 짧은 오버행으로 진보적인 전기차를 구현하기 위한 최상의 비율을 완성시켰습니다.\n",
      "현대자동차의 창조의 바탕에는 현대자동차만의 디자인 정신, 플루이딕 스컬프처(Fluidic Sculpture)’가 있습니다. 플루이딕 스컬프처는 자연을 모티브로 한 디자인을 가장 예술적인 방식으로 완성합니다. 살아있는 듯한 아름다움이 담긴 현대적이고 예술적인 조형. 예술혼과 정성을 다하여 빚은 디자인을 우리는 플루이딕 스컬프처라 부릅니다.\n",
      "하나의 선으로 완성된 것처럼 이음새 없이 이어지는 실루엣에는 간결한 구조를 뜻하는 ‘라이트 아키텍쳐’ 스타일이 적용됐습니다.\n",
      "외장의 감각적이고 스포티한 스타일은 내장 디자인으로 스며들어 차량 안팎에서 동일한 감성을 느낄 수 있습니다.\n",
      "전면부의 와이드한 프론트 후드는 차량의 존재감을 부각시키며, 파라메트릭 쥬얼을 캐스캐이딩 그릴에 일체화하여 보석과도 같은 감성을 구현하며 측면부의 깔끔하게 이어지는 캐릭터 라인과 함께 전체적으로 표현되는 풍부하고 세련된 볼륨감을 통해 감각적이고 스포티한 디자인을 구현했습니다.\n",
      "현대자동차 디자이너들에게 있어 핵심적인 디자인 원칙은 기능성을 온전히 경험할 수 있는 디자인을 한다는 것입니다.\n",
      "운전자의 직관적인 차량 조작을 돕는 21.5인치 크기의 파노라믹 플로팅 디스플레이 등 편의성을 높인 사용자 중심의 디자인이 적용됐습니다.\n",
      "패브릭 신소재, 리얼 우드 등 다양한 소재를 사용한 인테리어로 감성적이고 편안한 느낌을 전달하며 비행기의 환기시스템에서 영감을 받은 2-way 에어 벤틸레이션 시스템은 차량을 항상 쾌적한 상태로 유지합니다.\n",
      "주어진 Question : \n",
      " 현대자동차의 디자인 철학은 무엇인가요?\n",
      "생성된 Answer : \n",
      " [|user|]\n",
      "\n",
      "Question:현대자동차의 디자인 철학은 무엇인가요?\n",
      "\n",
      "Context:브랜드스토리 > Design | 현대자동차 - 현대닷컴 | 대한민국 대표 자동차회사 hyundai.com\n",
      "단순히 멋지고 아름다운 자동차가 아니라, 고객의 개성과 취향을 존중하는 디자인으로,\n",
      "고객 기대를 뛰어넘는 디자인 이상의 가치를 실현해 나갈 것입니다.\n",
      "\n",
      "이를 위해 현대자동차는 ‘센슈어스 스포티니스‘라는 동일한 디자인 철학 아래,\n",
      "각 차량의 독창성 역시 존중하는 디자인 방식을 추구해 나갈 계획입니다.\n",
      "심미적으로도 자연스러우며, 균형 잡힌 디자인을 구현했습니다.\n",
      "롱 휠 베이스와 큰 휠, 그리고 짧은 오버행으로 진보적인 전기차를 구현하기 위한 최상의 비율을 완성시켰습니다.\n",
      "현대자동차의 창조의 바탕에는 현대자동차만의 디자인 정신, 플루이딕 스컬프처(Fluidic Sculpture)’가 있습니다. 플루이딕 스컬프처는 자연을 모티브로 한 디자인을 가장 예술적인 방식으로 완성합니다. 살아있는 듯한 아름다움이 담긴 현대적이고 예술적인 조형. 예술혼과 정성을 다하여 빚은 디자인을 우리는 플루이딕 스컬프처라 부릅니다.\n",
      "하나의 선으로 완성된 것처럼 이음새 없이 이어지는 실루엣에는 간결한 구조를 뜻하는 ‘라이트 아키텍쳐’ 스타일이 적용됐습니다.\n",
      "외장의 감각적이고 스포티한 스타일은 내장 디자인으로 스며들어 차량 안팎에서 동일한 감성을 느낄 수 있습니다.\n",
      "전면부의 와이드한 프론트 후드는 차량의 존재감을 부각시키며, 파라메트릭 쥬얼을 캐스캐이딩 그릴에 일체화하여 보석과도 같은 감성을 구현하며 측면부의 깔끔하게 이어지는 캐릭터 라인과 함께 전체적으로 표현되는 풍부하고 세련된 볼륨감을 통해 감각적이고 스포티한 디자인을 구현했습니다.\n",
      "현대자동차 디자이너들에게 있어 핵심적인 디자인 원칙은 기능성을 온전히 경험할 수 있는 디자인을 한다는 것입니다.\n",
      "운전자의 직관적인 차량 조작을 돕는 21.5인치 크기의 파노라믹 플로팅 디스플레이 등 편의성을 높인 사용자 중심의 디자인이 적용됐습니다.\n",
      "패브릭 신소재, 리얼 우드 등 다양한 소재를 사용한 인테리어로 감성적이고 편안한 느낌을 전달하며 비행기의 환기시스템에서 영감을 받은 2-way 에어 벤틸레이션 시스템은 차량을 항상 쾌적한 상태로 유지합니다.\n",
      "\n",
      "Instruction:\n",
      "질문, 문맥(context), 그리고 답(Answer)이 주어졌을 때, 해당 답변에 대한 논리적 근거(Reasoning)를 작성하세요.\n",
      "다음의 포맷을 반드시 지켜주세요:\n",
      "##Reason: {reason}\n",
      "##Answer: {answer}\n",
      "[|endofturn|]\n",
      "[|assistant|]\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "##Reason: 주어진 문맥에서 현대자동차의 디자인 철학은 고객 중심의 개성 존중과 예술적 조형미를 강조하며, 특히 '플루이딕 스컬프처(Fluidic Sculpture)'와 라이트 아키텍처(Light Architecture)를 핵심 키워드로 삼고 있습니다. 이는 자연 모방과 기능성·감성 통합을 동시에 추구하는 현대자동차의 정체성을 반영합니다.  \n",
      "##Answer: 현대자동차의 디자인 철학은 고객의 개성과 취향을 존중하는 맞춤형 디자인과 예술적 조형미를 결합한 것으로, 플루이딕 스컬프처(자연을\n",
      "주어진 Question : \n",
      " 현대자동차의 디자인 정신은 무엇에 기반하고 있나요?\n",
      "생성된 Answer : \n",
      " [|user|]\n",
      "\n",
      "Question:현대자동차의 디자인 정신은 무엇에 기반하고 있나요?\n",
      "\n",
      "Context:브랜드스토리 > Design | 현대자동차 - 현대닷컴 | 대한민국 대표 자동차회사 hyundai.com\n",
      "단순히 멋지고 아름다운 자동차가 아니라, 고객의 개성과 취향을 존중하는 디자인으로,\n",
      "고객 기대를 뛰어넘는 디자인 이상의 가치를 실현해 나갈 것입니다.\n",
      "\n",
      "이를 위해 현대자동차는 ‘센슈어스 스포티니스‘라는 동일한 디자인 철학 아래,\n",
      "각 차량의 독창성 역시 존중하는 디자인 방식을 추구해 나갈 계획입니다.\n",
      "심미적으로도 자연스러우며, 균형 잡힌 디자인을 구현했습니다.\n",
      "롱 휠 베이스와 큰 휠, 그리고 짧은 오버행으로 진보적인 전기차를 구현하기 위한 최상의 비율을 완성시켰습니다.\n",
      "현대자동차의 창조의 바탕에는 현대자동차만의 디자인 정신, 플루이딕 스컬프처(Fluidic Sculpture)’가 있습니다. 플루이딕 스컬프처는 자연을 모티브로 한 디자인을 가장 예술적인 방식으로 완성합니다. 살아있는 듯한 아름다움이 담긴 현대적이고 예술적인 조형. 예술혼과 정성을 다하여 빚은 디자인을 우리는 플루이딕 스컬프처라 부릅니다.\n",
      "하나의 선으로 완성된 것처럼 이음새 없이 이어지는 실루엣에는 간결한 구조를 뜻하는 ‘라이트 아키텍쳐’ 스타일이 적용됐습니다.\n",
      "외장의 감각적이고 스포티한 스타일은 내장 디자인으로 스며들어 차량 안팎에서 동일한 감성을 느낄 수 있습니다.\n",
      "전면부의 와이드한 프론트 후드는 차량의 존재감을 부각시키며, 파라메트릭 쥬얼을 캐스캐이딩 그릴에 일체화하여 보석과도 같은 감성을 구현하며 측면부의 깔끔하게 이어지는 캐릭터 라인과 함께 전체적으로 표현되는 풍부하고 세련된 볼륨감을 통해 감각적이고 스포티한 디자인을 구현했습니다.\n",
      "현대자동차 디자이너들에게 있어 핵심적인 디자인 원칙은 기능성을 온전히 경험할 수 있는 디자인을 한다는 것입니다.\n",
      "운전자의 직관적인 차량 조작을 돕는 21.5인치 크기의 파노라믹 플로팅 디스플레이 등 편의성을 높인 사용자 중심의 디자인이 적용됐습니다.\n",
      "패브릭 신소재, 리얼 우드 등 다양한 소재를 사용한 인테리어로 감성적이고 편안한 느낌을 전달하며 비행기의 환기시스템에서 영감을 받은 2-way 에어 벤틸레이션 시스템은 차량을 항상 쾌적한 상태로 유지합니다.\n",
      "\n",
      "Instruction:\n",
      "질문, 문맥(context), 그리고 답(Answer)이 주어졌을 때, 해당 답변에 대한 논리적 근거(Reasoning)를 작성하세요.\n",
      "다음의 포맷을 반드시 지켜주세요:\n",
      "##Reason: {reason}\n",
      "##Answer: {answer}\n",
      "[|endofturn|]\n",
      "[|assistant|]\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "##Reason: 주어진 문맥에서 현대자동차의 디자인 정신은 고객 중심의 개성 존중, 스포티니스와 미학의 통합, 자연 모티프를 활용한 예술적 조형미, 그리고 사용자 경험 최적화에 기반합니다. 특히 '플루이딕 스컬프처'와 '라이트 아키텍처' 같은 혁신적인 디자인 철학이 핵심 요소로 제시되었으며, 이는 기능성과 감성적 만족을 동시에 추구하는 현대자동차의 전략적 접근을 반영합니다.  \n",
      "##Answer: 현대자동차의 디자인 정신은 고객의 개성과 취향 존중, 스포티한 미학과 예술적 조형\n",
      "주어진 Question : \n",
      " 현대자동차의 외장 디자인 특징은 무엇인가요?\n",
      "생성된 Answer : \n",
      " [|user|]\n",
      "\n",
      "Question:현대자동차의 외장 디자인 특징은 무엇인가요?\n",
      "\n",
      "Context:브랜드스토리 > Design | 현대자동차 - 현대닷컴 | 대한민국 대표 자동차회사 hyundai.com\n",
      "단순히 멋지고 아름다운 자동차가 아니라, 고객의 개성과 취향을 존중하는 디자인으로,\n",
      "고객 기대를 뛰어넘는 디자인 이상의 가치를 실현해 나갈 것입니다.\n",
      "\n",
      "이를 위해 현대자동차는 ‘센슈어스 스포티니스‘라는 동일한 디자인 철학 아래,\n",
      "각 차량의 독창성 역시 존중하는 디자인 방식을 추구해 나갈 계획입니다.\n",
      "심미적으로도 자연스러우며, 균형 잡힌 디자인을 구현했습니다.\n",
      "롱 휠 베이스와 큰 휠, 그리고 짧은 오버행으로 진보적인 전기차를 구현하기 위한 최상의 비율을 완성시켰습니다.\n",
      "현대자동차의 창조의 바탕에는 현대자동차만의 디자인 정신, 플루이딕 스컬프처(Fluidic Sculpture)’가 있습니다. 플루이딕 스컬프처는 자연을 모티브로 한 디자인을 가장 예술적인 방식으로 완성합니다. 살아있는 듯한 아름다움이 담긴 현대적이고 예술적인 조형. 예술혼과 정성을 다하여 빚은 디자인을 우리는 플루이딕 스컬프처라 부릅니다.\n",
      "하나의 선으로 완성된 것처럼 이음새 없이 이어지는 실루엣에는 간결한 구조를 뜻하는 ‘라이트 아키텍쳐’ 스타일이 적용됐습니다.\n",
      "외장의 감각적이고 스포티한 스타일은 내장 디자인으로 스며들어 차량 안팎에서 동일한 감성을 느낄 수 있습니다.\n",
      "전면부의 와이드한 프론트 후드는 차량의 존재감을 부각시키며, 파라메트릭 쥬얼을 캐스캐이딩 그릴에 일체화하여 보석과도 같은 감성을 구현하며 측면부의 깔끔하게 이어지는 캐릭터 라인과 함께 전체적으로 표현되는 풍부하고 세련된 볼륨감을 통해 감각적이고 스포티한 디자인을 구현했습니다.\n",
      "현대자동차 디자이너들에게 있어 핵심적인 디자인 원칙은 기능성을 온전히 경험할 수 있는 디자인을 한다는 것입니다.\n",
      "운전자의 직관적인 차량 조작을 돕는 21.5인치 크기의 파노라믹 플로팅 디스플레이 등 편의성을 높인 사용자 중심의 디자인이 적용됐습니다.\n",
      "패브릭 신소재, 리얼 우드 등 다양한 소재를 사용한 인테리어로 감성적이고 편안한 느낌을 전달하며 비행기의 환기시스템에서 영감을 받은 2-way 에어 벤틸레이션 시스템은 차량을 항상 쾌적한 상태로 유지합니다.\n",
      "\n",
      "Instruction:\n",
      "질문, 문맥(context), 그리고 답(Answer)이 주어졌을 때, 해당 답변에 대한 논리적 근거(Reasoning)를 작성하세요.\n",
      "다음의 포맷을 반드시 지켜주세요:\n",
      "##Reason: {reason}\n",
      "##Answer: {answer}\n",
      "[|endofturn|]\n",
      "[|assistant|]\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "##Reason: 주어진 문맥에서 현대자동차의 외장 디자인 특징은 '센슈어스 스포티니스'와 '플루이딕 스컬프처'를 중심으로 설명되어 있습니다. 특히, 롱 휠 베이스와 짧은 오버행을 활용한 진보적인 비율, 이음새 없는 라이트 아키텍처 스타일, 파라메트릭 Jewel캐스팅 그릴, 그리고 자연 모티프를 반영한 예술적인 조형미 등이 핵심 요소로 언급되었습니다. 또한 감각적이고 스포티한 전면부 디자인과 사용자 중심의 편의성 기능 통합이 강조되어 있습니다.\n",
      "\n",
      "##\n",
      "주어진 Question : \n",
      " 현대자동차의 인테리어 디자인은 어떤 소재를 사용하나요?\n",
      "생성된 Answer : \n",
      " [|user|]\n",
      "\n",
      "Question:현대자동차의 인테리어 디자인은 어떤 소재를 사용하나요?\n",
      "\n",
      "Context:브랜드스토리 > Design | 현대자동차 - 현대닷컴 | 대한민국 대표 자동차회사 hyundai.com\n",
      "단순히 멋지고 아름다운 자동차가 아니라, 고객의 개성과 취향을 존중하는 디자인으로,\n",
      "고객 기대를 뛰어넘는 디자인 이상의 가치를 실현해 나갈 것입니다.\n",
      "\n",
      "이를 위해 현대자동차는 ‘센슈어스 스포티니스‘라는 동일한 디자인 철학 아래,\n",
      "각 차량의 독창성 역시 존중하는 디자인 방식을 추구해 나갈 계획입니다.\n",
      "심미적으로도 자연스러우며, 균형 잡힌 디자인을 구현했습니다.\n",
      "롱 휠 베이스와 큰 휠, 그리고 짧은 오버행으로 진보적인 전기차를 구현하기 위한 최상의 비율을 완성시켰습니다.\n",
      "현대자동차의 창조의 바탕에는 현대자동차만의 디자인 정신, 플루이딕 스컬프처(Fluidic Sculpture)’가 있습니다. 플루이딕 스컬프처는 자연을 모티브로 한 디자인을 가장 예술적인 방식으로 완성합니다. 살아있는 듯한 아름다움이 담긴 현대적이고 예술적인 조형. 예술혼과 정성을 다하여 빚은 디자인을 우리는 플루이딕 스컬프처라 부릅니다.\n",
      "하나의 선으로 완성된 것처럼 이음새 없이 이어지는 실루엣에는 간결한 구조를 뜻하는 ‘라이트 아키텍쳐’ 스타일이 적용됐습니다.\n",
      "외장의 감각적이고 스포티한 스타일은 내장 디자인으로 스며들어 차량 안팎에서 동일한 감성을 느낄 수 있습니다.\n",
      "전면부의 와이드한 프론트 후드는 차량의 존재감을 부각시키며, 파라메트릭 쥬얼을 캐스캐이딩 그릴에 일체화하여 보석과도 같은 감성을 구현하며 측면부의 깔끔하게 이어지는 캐릭터 라인과 함께 전체적으로 표현되는 풍부하고 세련된 볼륨감을 통해 감각적이고 스포티한 디자인을 구현했습니다.\n",
      "현대자동차 디자이너들에게 있어 핵심적인 디자인 원칙은 기능성을 온전히 경험할 수 있는 디자인을 한다는 것입니다.\n",
      "운전자의 직관적인 차량 조작을 돕는 21.5인치 크기의 파노라믹 플로팅 디스플레이 등 편의성을 높인 사용자 중심의 디자인이 적용됐습니다.\n",
      "패브릭 신소재, 리얼 우드 등 다양한 소재를 사용한 인테리어로 감성적이고 편안한 느낌을 전달하며 비행기의 환기시스템에서 영감을 받은 2-way 에어 벤틸레이션 시스템은 차량을 항상 쾌적한 상태로 유지합니다.\n",
      "\n",
      "Instruction:\n",
      "질문, 문맥(context), 그리고 답(Answer)이 주어졌을 때, 해당 답변에 대한 논리적 근거(Reasoning)를 작성하세요.\n",
      "다음의 포맷을 반드시 지켜주세요:\n",
      "##Reason: {reason}\n",
      "##Answer: {answer}\n",
      "[|endofturn|]\n",
      "[|assistant|]\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "##Reason: 주어진 문맥에서 현대자동차의 인테리어 소재 사용 근거는 다음과 같습니다.  \n",
      "- **플루이딕 스컬프처 적용**: 자연 모티브의 예술적 디자인 철학 하에 리얼 우드, 합성수지 등 다양한 신소재를 활용해 감성적이고 유기적인 느낌을 구현했습니다.  \n",
      "- **기능성 강조**: 에어 벤틸레이션 시스템과 같은 기술적 요소를 내장재(패브릭, 패널 등)와 결합해 실용성과 미학을 동시에 충족시켰습니다.  \n",
      "- **통합 디자인 전략**: 외부 프론트 그릴의 파라메트\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 57\u001b[0m\n\u001b[0;32m     47\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     48\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt\u001b[38;5;241m.\u001b[39mformat(question\u001b[38;5;241m=\u001b[39mquestion, context\u001b[38;5;241m=\u001b[39mcontext)}\n\u001b[0;32m     49\u001b[0m ]\n\u001b[0;32m     50\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[0;32m     51\u001b[0m     messages,\n\u001b[0;32m     52\u001b[0m     tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     53\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     54\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m )\n\u001b[1;32m---> 57\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     58\u001b[0m     input_ids\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m     59\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m     60\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     61\u001b[0m )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m주어진 Question : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, question)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m생성된 Answer : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2634\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2626\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2627\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2628\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2629\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2630\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2631\u001b[0m     )\n\u001b[0;32m   2633\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2634\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2635\u001b[0m         input_ids,\n\u001b[0;32m   2636\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2637\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2638\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2639\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2640\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2641\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2642\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2645\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[0;32m   2646\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2647\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2648\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2649\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2650\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2651\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3618\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3616\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3618\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3621\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3622\u001b[0m     outputs,\n\u001b[0;32m   3623\u001b[0m     model_kwargs,\n\u001b[0;32m   3624\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3625\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\accelerate\\hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:959\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[1;32m--> 959\u001b[0m output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    961\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\transformers\\models\\exaone4\\modeling_exaone4.py:491\u001b[0m, in \u001b[0;36mExaone4ForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[0;32m    458\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[0;32m    459\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;124;03m    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;124;03m        Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m \n\u001b[0;32m    490\u001b[0m \u001b[38;5;124;03m    NOTE: `EXAONE-4.0-Instruct` is a placeholder model ID. The exact model ID will be updated in the future.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 491\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m    492\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    493\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    494\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    495\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    496\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    497\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    498\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:1083\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m                 module\u001b[38;5;241m.\u001b[39mforward \u001b[38;5;241m=\u001b[39m make_capture_wrapper(module, original_forward, key, specs\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   1081\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[1;32m-> 1083\u001b[0m outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\transformers\\models\\exaone4\\modeling_exaone4.py:404\u001b[0m, in \u001b[0;36mExaone4Model.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m    403\u001b[0m     layer_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_types[i]\n\u001b[1;32m--> 404\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m    405\u001b[0m         hidden_states,\n\u001b[0;32m    406\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    407\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask_mapping[layer_type],\n\u001b[0;32m    408\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    409\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    410\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    411\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    413\u001b[0m     )\n\u001b[0;32m    415\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[0;32m    418\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    419\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\accelerate\\hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\transformers\\models\\exaone4\\modeling_exaone4.py:306\u001b[0m, in \u001b[0;36mExaone4DecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[0;32m    305\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 306\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    307\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_feedforward_layernorm(hidden_states)\n\u001b[0;32m    308\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\accelerate\\hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\transformers\\models\\exaone4\\modeling_exaone4.py:265\u001b[0m, in \u001b[0;36mExaone4MLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 265\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\accelerate\\hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\jinhy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%writefile qa_context_basemodel_test.py\n",
    "from textwrap import dedent\n",
    "import json\n",
    "import os\n",
    "\n",
    "# answer 가 너무 단순한 단어 조합 -> 프롬프트 엔지니어링\n",
    "# 아니면 32B 로 테스트 ?\n",
    "JSONL_PATH = \"QA_context/현대 디자인 모토.jsonl\"\n",
    "\n",
    "prompt = dedent(\"\"\"\n",
    "Question:{question}\n",
    "\n",
    "Context:{context}\n",
    "\n",
    "Instruction:\n",
    "질문, 문맥(context), 그리고 답(Answer)이 주어졌을 때, 해당 답변에 대한 논리적 근거(Reasoning)를 작성하세요.\n",
    "다음의 포맷을 반드시 지켜주세요:\n",
    "##Reason: {{reason}}\n",
    "##Answer: {{answer}}\n",
    "\"\"\")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"LGAI-EXAONE/EXAONE-4.0-1.2B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "jsonl_path = JSONL_PATH\n",
    "with open(jsonl_path, encoding=\"utf-8\") as f:\n",
    "    datas = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:  # 빈 줄 건너뛰기\n",
    "            datas.append(json.loads(line))\n",
    "\n",
    "for data in datas:\n",
    "    context = data[\"context\"]\n",
    "    messages = data[\"messages\"]\n",
    "    print(f\"주어진 Context : \\n\", context)\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            question = message[\"content\"]\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": prompt.format(question=question, context=context)}\n",
    "            ]\n",
    "            input_ids = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=True,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            output = model.generate(\n",
    "                input_ids.to(model.device),\n",
    "                max_new_tokens=128,\n",
    "                do_sample=False,\n",
    "            )\n",
    "            print(f\"주어진 Question : \\n\", question)\n",
    "            print(f\"생성된 Answer : \\n\", tokenizer.decode(output[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420fec0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prompt\u001b[38;5;241m.\u001b[39mformat(question\u001b[38;5;241m=\u001b[39mquestion)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'context'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09185db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
