{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dfdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv(\"key.env\")\n",
    "hf_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "login(hf_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f0ffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 26 files: 100%|██████████| 26/26 [00:17<00:00,  1.49it/s]\n",
      "Loading pipeline components...:  22%|██▏       | 2/9 [00:03<00:11,  1.69s/it]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Loading pipeline components...:  56%|█████▌    | 5/9 [00:06<00:05,  1.33s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.99s/it]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00, 10.89s/it]\u001b[A\n",
      "Loading pipeline components...: 100%|██████████| 9/9 [00:29<00:00,  3.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusion3Pipeline {\n",
       "  \"_class_name\": \"StableDiffusion3Pipeline\",\n",
       "  \"_diffusers_version\": \"0.35.0.dev0\",\n",
       "  \"_name_or_path\": \"stabilityai/stable-diffusion-3.5-medium\",\n",
       "  \"feature_extractor\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"FlowMatchEulerDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModelWithProjection\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModelWithProjection\"\n",
       "  ],\n",
       "  \"text_encoder_3\": [\n",
       "    \"transformers\",\n",
       "    \"T5EncoderModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_3\": [\n",
       "    \"transformers\",\n",
       "    \"T5TokenizerFast\"\n",
       "  ],\n",
       "  \"transformer\": [\n",
       "    \"diffusers\",\n",
       "    \"SD3Transformer2DModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import StableDiffusion3Pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"stabilityai/stable-diffusion-3.5-medium\"\n",
    "pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "pipe.to(\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
