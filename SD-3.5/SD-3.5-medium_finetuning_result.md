# SD-3.5-medium 파인튜닝 결과 보고서

## 1. 실험 개요
- **모델**: `stabilityai/stable-diffusion-3.5-medium`
- **파인튜닝 방식**: LoRA 기반 미세조정(Fine-tuning)
- **파인튜닝 도구**: **SimpleTuner** 활용
- **데이터셋**: 이미지-캡션 쌍 100개 (학습/테스트 동일 데이터)
- **목표**: 베이스(Base) 모델과 파인튜닝(LoRA) 모델의 **이미지 생성 품질 비교**
- **평가 지표**
  - **CLIP Score**: 프롬프트와 생성 이미지 간의 의미적 유사도
  - **FID (Fréchet Inception Distance)**: 원본 이미지와 생성 이미지 간의 분포 차이
- **실험 환경**
  - **시드값(Seed)**: **42**로 고정하여 재현성 확보

---

## 2. 실험 조건

### 1차 실험
```json
{
  "num_train_epochs": 2,
  "max_train_steps": 1000
}
```

#### CLIP Score (Prompt 10개)

| 모델 | 평균 |
| --- | --- |
| Base | 26.6794 |
| LoRA | 27.7876 |

➡ **LoRA 모델이 평균 약 1.1점 상승**

---

### 2차 실험
```json
{
  "num_train_epochs": 5,
  "max_train_steps": 3000
}
```

#### CLIP Score (Prompt 10개)

| 모델 | 평균 |
| --- | --- |
| Base | 26.6794 |
| LoRA | 27.0537 |

➡ **LoRA 모델이 평균 약 0.4점 상승**

---

## 3. FID Score 비교

| 실험 조건 | Base | LoRA | 변화 |
| --- | --- | --- | --- |
| 1차(2 epoch, 1000 steps) | 10.5939 | 4.0336 | ↓ **많이 개선** |
| 2차(5 epoch, 3000 steps) | 10.5939 | 8.6304 | ↓ **소폭 개선** |

---

## 4. 분석

1. **1차 실험 결과**
   - CLIP 점수에서 LoRA 모델이 전반적으로 **유의미한 상승**(평균 +1.1).
   - FID 점수도 크게 낮아져(10.59 → 4.03) **이미지 품질 향상**이 확인됨.
   - 적은 epoch에서도 효율적인 성능 개선 가능성을 확인.

2. **2차 실험 결과**
   - CLIP 점수는 소폭 향상(+0.4)했으나, 개선 폭이 줄어듦.
   - FID 점수도 소폭 개선(10.59 → 8.63)되었지만, 1차 실험 대비 효과가 낮음.
   - 장기 학습 시 **과적합(Overfitting)** 가능성을 시사.

3. **종합 결론**
   - **LoRA 기반 파인튜닝은 적절한 학습 스텝에서 성능 향상에 효과적**.
   - 지나친 학습 스텝은 생성 다양성과 품질이 저하될 수 있음.
   - 최적 학습 스텝은 1000~2000 사이에서 탐색 필요.

---

## 5. 향후 개선 방향
- 데이터 다양성 확보 및 augmentation 적용.
- 학습 스텝 별 중간 체크포인트 저장 후 비교.
- CLIP 외에도 **LPIPS**, **Inception Score(IS)** 등 추가 지표 활용.
- 다양한 프롬프트 스타일(짧은 문장, 세부 묘사 포함)로 평가 확장.

---

## 6. 전반적인 실험 고찰
본 실험은 **SimpleTuner**를 사용하여 `stabilityai/stable-diffusion-3.5-medium` 모델을 LoRA 방식으로 파인튜닝하고, 동일한 시드값(42) 하에서 결과를 비교함으로써 재현성을 보장했다.  
실험 결과, **적절한 학습 스텝에서 CLIP Score와 FID Score 모두 유의미하게 개선**됨을 확인했으며, 특히 1차 실험에서는 데이터 수가 적음에도 불구하고 품질이 크게 향상되었다. 반면, 학습을 장기간 진행한 2차 실험에서는 과적합으로 인한 성능 저하 가능성이 나타났다.  
이는 이미지 생성 모델에서 **데이터 규모, 학습 스텝, 프롬프트 다양성**이 결과 품질에 큰 영향을 미친다는 점을 보여주며, 추후 실험에서는 더 다양한 데이터와 정밀한 하이퍼파라미터 조정이 필요하다는 시사점을 제공한다.  
