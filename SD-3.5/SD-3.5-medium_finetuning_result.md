# SD-3.5-medium 파인튜닝 결과 보고서

## 1. 실험 개요
- **모델**: `stabilityai/stable-diffusion-3.5-medium`
- **파인튜닝 방식**: LoRA 기반 미세조정(Fine-tuning)
- **데이터셋**: 이미지-캡션 쌍 100개 (학습/테스트 동일 데이터)
- **목표**: 베이스(Base) 모델과 파인튜닝(LoRA) 모델의 **이미지 생성 품질 비교**
- **평가 지표**
  - **CLIP Score**: 프롬프트와 생성 이미지 간의 의미적 유사도
  - **FID (Fréchet Inception Distance)**: 원본 이미지와 생성 이미지 간의 분포 차이

---

## 2. 실험 조건

### 1차 실험
```json
{
  "num_train_epochs": 2,
  "max_train_steps": 1000
}
```

#### CLIP Score (Prompt 10개)

**평균 CLIP Score**

| 모델 | 평균 |
| --- | --- |
| Base | 26.6794 |
| LoRA | 27.7876 |

➡ **LoRA 모델이 평균 약 1.1점 상승**

---

### 2차 실험
```json
{
  "num_train_epochs": 5,
  "max_train_steps": 3000
}
```

#### CLIP Score (Prompt 10개)

**평균 CLIP Score**

| 모델 | 평균 |
| --- | --- |
| Base | 26.6794 |
| LoRA | 27.0537 |

➡ **LoRA 모델이 평균 약 0.4점 상승**

---

## 3. FID Score 비교

| 실험 조건 | Base | LoRA | 변화 |
| --- | --- | --- | --- |
| 1차(2 epoch, 1000 steps) | 10.5939 | 4.0336 | ↓ **많이 개선** |
| 2차(5 epoch, 3000 steps) | 10.5939 | 8.6304 | ↑ **소폭 개선** |

---

## 4. 분석

1. **1차 실험 결과**
   - CLIP 점수에서 LoRA 모델이 전반적으로 **유의미한 상승**(평균 +1.1).
   - FID 점수도 낮아져(10.59 → 4.03) **이미지 품질 향상**이 확인됨.
   - 적은 epoch에서도 효율적인 성능 개선 가능성을 확인.

2. **2차 실험 결과**
   - CLIP 점수는 소폭 향상(+0.4)으로 **소폭 감소**.
   - FID 점수도 소폭 향상(10.59 → 8.63), 1차 실험과 대조했을 때 장기 학습 시 **과적합(Overfitting)** 가능성 시사.
   - 일부 프롬프트에서 오히려 점수가 하락.

3. **종합 결론**
   - **LoRA 기반 파인튜닝은 적절한 학습 스텝에서 성능 향상에 효과적**.
   - 지나친 학습 스텝은 데이터 과적합으로 인해 **생성 다양성과 품질이 저하**될 수 있음.
   - 최적 학습 스텝은 1000~2000 사이에서 탐색 필요.

---

## 5. 향후 개선 방향
- 데이터 다양성 확보 및 augmentation 적용.
- 학습 스텝 별 중간 체크포인트 저장 후 비교.
- CLIP 외에도 **LPIPS**나 **Inception Score(IS)** 등 추가 지표 활용.
- 다양한 프롬프트 스타일(짧은 문장, 세부 묘사 포함)로 평가 확장.
