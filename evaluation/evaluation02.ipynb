{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5e4866-dc50-468f-9235-bc8ddefe4849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.8.0.dev20250319+cu128)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.17.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch) (77.0.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting matplotlib (from bert-score)\n",
      "  Downloading matplotlib-3.10.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->bert-score)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->bert-score)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->bert-score)\n",
      "  Downloading fonttools-4.59.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (107 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->bert-score)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->bert-score) (2.4.7)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Downloading transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m364.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.17.0-py3-none-any.whl (503 kB)\n",
      "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m376.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m178.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m308.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m238.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m388.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading matplotlib-3.10.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m383.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m391.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m333.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m444.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m388.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, tabulate, safetensors, regex, pyarrow, propcache, multidict, kiwisolver, hf-xet, frozenlist, fonttools, dill, cycler, contourpy, aiohappyeyeballs, yarl, pandas, multiprocess, matplotlib, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, accelerate, peft, datasets, bert-score\n",
      "Successfully installed accelerate-1.10.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 bert-score-0.3.13 contourpy-1.3.3 cycler-0.12.1 datasets-4.0.0 dill-0.3.8 fonttools-4.59.0 frozenlist-1.7.0 hf-xet-1.1.7 huggingface-hub-0.34.4 kiwisolver-1.4.9 matplotlib-3.10.5 multidict-6.6.4 multiprocess-0.70.16 pandas-2.3.1 peft-0.17.0 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 regex-2025.7.34 safetensors-0.6.2 tabulate-0.9.0 tokenizers-0.21.4 tqdm-4.67.1 transformers-4.55.0 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers peft accelerate datasets bert-score pandas tqdm tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c325222-5e8e-4adf-b292-c1e19804a07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea0bb0a-5866-4cc3-b7a8-76f5ff391d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 중: ./exaone_4.0_1.2b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fddeef445fa477ca53a745fe571f81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 베이스 모델 로드 완료\n",
      "\n",
      "--- 베이스 모델 답변 생성 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "베이스 모델: 100%|██████████| 4/4 [00:48<00:00, 12.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 중: ./exaone_4.0_1.2b + ./llm_finetuned_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1f1fddfe2649f4ad1353bb145f6b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 파인튜닝 모델 로드 및 병합 완료\n",
      "\n",
      "--- 파인튜닝 모델 답변 생성 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "파인튜닝 모델: 100%|██████████| 4/4 [00:49<00:00, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 결과를 qualitative_comparison_v5.md 파일로 저장 중 ---\n",
      "✅ 정성 평가용 데이터 생성이 완료되었습니다. 'qualitative_comparison_v5.md' 파일을 확인해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "(수정-v2) 베이스 모델과 파인튜닝된 모델의 답변 품질을 정성적으로 비교 평가하기 위한 스크립트.\n",
    "\n",
    "변경 사항:\n",
    "- 최종 목표인 '새로운 디자인 생성' 능력에 초점을 맞춤.\n",
    "- 창의적인 컨셉을 제시하고, 그에 맞는 구체적인 디자인 요소를 '생성'하도록 유도하는 질문으로 구성.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 설정 ---\n",
    "BASE_MODEL_PATH = \"./exaone_4.0_1.2b\"\n",
    "ADAPTER_PATH = \"./llm_finetuned_model\"\n",
    "OUTPUT_MD_PATH = \"qualitative_comparison_v5.md\"\n",
    "\n",
    "# 새로운 디자인을 '생성'하는 능력을 평가하기 위한 질문 목록\n",
    "QUESTIONS = [\n",
    "    # --- 컨셉 기반 신규 디자인 생성 ---\n",
    "    \"'한국의 전통적인 한옥과 수묵화'를 컨셉으로 제네시스 G90의 새로운 스페셜 에디션 모델을 디자인해줘. 특히 크레스트 그릴, 휠, 실내 내장재의 디자인이 어떻게 바뀔지 구체적으로 묘사해줘.\",\n",
    "    \"2050년 미래 해양 도시를 탐험하기 위한 '현대 포세이돈'이라는 이름의 수륙양용 SUV를 상상해서 디자인해줘. 공기역학적인 차체, 잠수 모드를 위한 헤드라이트, 물 속 추진을 위한 휠의 변형 디자인을 중심으로.\",\n",
    "    \n",
    "    # --- 특정 디자인 요소의 창의적 융합 및 재해석 ---\n",
    "    \"현대자동차의 '파라메트릭 픽셀'과 제네시스의 '두 줄' 디자인을 융합해서, 새로운 전기 스포츠카의 테일램프 디자인을 만들어줘. 어떤 모양일지 아주 상세하게 설명해줘.\",\n",
    "    \n",
    "    # --- 브랜드 아이덴티티 기반의 새로운 모델 생성 ---\n",
    "    \"현대의 고성능 'N' 브랜드에서 최초의 오프로드용 픽업트럭을 만든다면 어떤 모습일까? 'N' 브랜드의 상징색, 공격적인 범퍼 디자인, 그리고 거친 지형을 위한 타이어와 휠 디자인을 구체적으로 설명해줘.\"\n",
    "]\n",
    "\n",
    "def load_model(model_path, adapter_path=None):\n",
    "    \"\"\"모델과 토크나이저를 로드하는 통합 함수\"\"\"\n",
    "    print(f\"모델 로드 중: {model_path}\" + (f\" + {adapter_path}\" if adapter_path else \"\"))\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    if adapter_path:\n",
    "        model = PeftModel.from_pretrained(model, adapter_path)\n",
    "        model = model.merge_and_unload()\n",
    "        print(\"✅ 파인튜닝 모델 로드 및 병합 완료\")\n",
    "    else:\n",
    "        print(\"✅ 베이스 모델 로드 완료\")\n",
    "        \n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_answer(model, tokenizer, question):\n",
    "    \"\"\"주어진 모델과 질문으로 답변을 생성하는 함수\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    try:\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "        \n",
    "        # 창의적이고 상세한 생성을 위해 옵션 유지\n",
    "        output = model.generate(\n",
    "            input_ids, \n",
    "            max_new_tokens=512, \n",
    "            do_sample=True, \n",
    "            temperature=0.8,\n",
    "            top_p=0.9,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.1 # 반복을 줄여 좀 더 창의적인 결과 유도\n",
    "        )\n",
    "        \n",
    "        full_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        answer = full_text.split(\"assistant\\n\")[1].strip() if \"assistant\\n\" in full_text else full_text\n",
    "\n",
    "        answer = answer.replace(\"\\n\", \"<br>\").replace(\"|\", \"&#124;\")\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f\"답변 생성 중 오류 발생: {str(e)}\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    base_model, tokenizer = load_model(BASE_MODEL_PATH)\n",
    "    base_answers = []\n",
    "    print(\"\\n--- 베이스 모델 답변 생성 시작 ---\")\n",
    "    for q in tqdm(QUESTIONS, desc=\"베이스 모델\"):\n",
    "        base_answers.append(generate_answer(base_model, tokenizer, q))\n",
    "    del base_model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ft_model, tokenizer = load_model(BASE_MODEL_PATH, ADAPTER_PATH)\n",
    "    ft_answers = []\n",
    "    print(\"\\n--- 파인튜닝 모델 답변 생성 시작 ---\")\n",
    "    for q in tqdm(QUESTIONS, desc=\"파인튜닝 모델\"):\n",
    "        ft_answers.append(generate_answer(ft_model, tokenizer, q))\n",
    "    del ft_model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n--- 결과를 {OUTPUT_MD_PATH} 파일로 저장 중 ---\")\n",
    "    with open(OUTPUT_MD_PATH, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# 모델별 답변 정성 평가 (v2 - 창의적 디자인 생성 중심)\\n\\n\")\n",
    "        f.write(\"| 질문 (Creative Brief) | 베이스 모델 답변 (Base Model) | 파인튜닝 모델 답변 (Finetuned Model) |\\n\")\n",
    "        f.write(\"|---|---|---|\")\n",
    "        for i in range(len(QUESTIONS)):\n",
    "            f.write(f\"| {QUESTIONS[i]} | {base_answers[i]} | {ft_answers[i]} |\\n\")\n",
    "\n",
    "    print(f\"✅ 정성 평가용 데이터 생성이 완료되었습니다. '{OUTPUT_MD_PATH}' 파일을 확인해주세요.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e96331e-55f2-479e-91ed-3a85af399ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 40개의 평가 데이터를 로드했습니다.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfeda03bd4324388904387c5f2acab1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [Base Model] 모델 답변 생성 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "평가 중 [Base Model]: 100%|██████████| 40/40 [02:50<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Base Model] BERTScore 계산 중 ---\n",
      "✅ [Base Model] 평가 완료\n",
      "\n",
      "--- [Base Model] 전체 평균 점수 --- BERTScore-P     0.648318\n",
      "BERTScore-R     0.680015\n",
      "BERTScore-F1    0.662373\n",
      "dtype: float64\n",
      "✅ 베이스 모델 평가 결과가 improved_base_model_evaluation02.md 파일에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce178963bd474457b0234a4548c419cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [Finetuned Model] 모델 답변 생성 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "평가 중 [Finetuned Model]: 100%|██████████| 40/40 [02:49<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Finetuned Model] BERTScore 계산 중 ---\n",
      "✅ [Finetuned Model] 평가 완료\n",
      "\n",
      "--- [Finetuned Model] 전체 평균 점수 --- BERTScore-P     0.676636\n",
      "BERTScore-R     0.705634\n",
      "BERTScore-F1    0.689715\n",
      "dtype: float64\n",
      "✅ 파인튜닝 모델 평가 결과가 finetuned_model_evaluation02.md 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "개선된 프롬프트(Chat Template)를 사용하여 모델의 정량 평가를 수행하는 스크립트.\n",
    "\n",
    "기존 방식의 한계:\n",
    "- `Question: {question}Answer:` 형식의 단순한 프롬프트는\n",
    "  모델이 가진 본래의 대화/지시사항 처리 능력을 제대로 활용하지 못할 수 있습니다.\n",
    "\n",
    "개선된 방식:\n",
    "- `tokenizer.apply_chat_template`을 사용하여 모델이 학습된 형식에 맞는\n",
    "  최적의 프롬프트를 자동으로 생성합니다. 이를 통해 모델의 성능을 더 정확하게 측정할 수 있습니다.\n",
    "- 각 모델(베이스, 파인튜닝)의 평가를 별도의 함수로 분리하여 코드의 명확성과 재사용성을 높였습니다.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import bert_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 공통 설정 ---\n",
    "BASE_MODEL_PATH = \"./exaone_4.0_1.2b\"\n",
    "ADAPTER_PATH = \"./llm_finetuned_model\"\n",
    "TEST_DATA_PATH = './test.jsonl'\n",
    "\n",
    "def evaluate_model(model_name, model, tokenizer, data):\n",
    "    \"\"\"주어진 모델에 대해 평가를 수행하고 결과를 반환하는 함수\"\"\"\n",
    "    print(f\"\\n--- [{model_name}] 모델 답변 생성 시작 ---\")\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for item in tqdm(data, desc=f\"평가 중 [{model_name}]\"):\n",
    "        question = item['messages'][0]['content']\n",
    "        reference_answer = item['messages'][1]['content']\n",
    "        \n",
    "        # 개선된 프롬프트: tokenizer의 chat template 사용\n",
    "        messages = [{\"role\": \"user\", \"content\": question}]\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        \n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "        \n",
    "        # do_sample=False는 기존 노트북과 동일한 환경을 위함. True로 바꾸면 더 나은 결과가 나올 수 있음.\n",
    "        output = model.generate(\n",
    "            input_ids, \n",
    "            max_new_tokens=256, \n",
    "            do_sample=False, \n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        # 프롬프트 부분을 제거하고 답변만 추출 (chat template 결과에 따라 후처리 방식이 달라질 수 있음)\n",
    "        answer = generated_text[len(prompt):].strip()\n",
    "        \n",
    "        predictions.append(answer)\n",
    "        references.append(reference_answer)\n",
    "\n",
    "    print(f\"--- [{model_name}] BERTScore 계산 중 ---\")\n",
    "    bert_p, bert_r, bert_f1 = bert_score.score(\n",
    "        predictions, references, lang=\"ko\", model_type=\"bert-base-multilingual-cased\", verbose=False\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for i in range(len(predictions)):\n",
    "        results.append({\n",
    "            \"Question\": data[i]['messages'][0]['content'],\n",
    "            \"Reference Answer\": references[i],\n",
    "            \"Generated Answer\": predictions[i],\n",
    "            \"BERTScore-P\": bert_p[i].item(),\n",
    "            \"BERTScore-R\": bert_r[i].item(),\n",
    "            \"BERTScore-F1\": bert_f1[i].item()\n",
    "        })\n",
    "        \n",
    "    print(f\"✅ [{model_name}] 평가 완료\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    # --- 데이터 로드 ---\n",
    "    with open(TEST_DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "        test_data = [json.loads(line) for line in f if line.strip()]\n",
    "    print(f\"✅ 총 {len(test_data)}개의 평가 데이터를 로드했습니다.\")\n",
    "\n",
    "    # --- 1. 베이스 모델 평가 ---\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "    \n",
    "    base_results_df = evaluate_model(\"Base Model\", base_model, tokenizer, test_data)\n",
    "    \n",
    "    # 결과 저장 및 출력\n",
    "    base_avg_scores = base_results_df[[col for col in base_results_df.columns if \"BERTScore\" in col]].mean()\n",
    "    print(\"\\n--- [Base Model] 전체 평균 점수 ---\\\n",
    "\", base_avg_scores)\n",
    "    base_results_df.to_markdown(\"./base_model_evaluation02.md\", index=False)\n",
    "    print(\"✅ 베이스 모델 평가 결과가 improved_base_model_evaluation02.md 파일에 저장되었습니다.\")\n",
    "    \n",
    "    del base_model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # --- 2. 파인튜닝 모델 평가 ---\n",
    "    # 베이스 모델을 다시 로드해야 PEFT 적용 가능\n",
    "    base_model_for_peft = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "    finetuned_model = PeftModel.from_pretrained(base_model_for_peft, ADAPTER_PATH)\n",
    "    finetuned_model = finetuned_model.merge_and_unload()\n",
    "    \n",
    "    ft_results_df = evaluate_model(\"Finetuned Model\", finetuned_model, tokenizer, test_data)\n",
    "\n",
    "    # 결과 저장 및 출력\n",
    "    ft_avg_scores = ft_results_df[[col for col in ft_results_df.columns if \"BERTScore\" in col]].mean()\n",
    "    print(\"\\n--- [Finetuned Model] 전체 평균 점수 ---\\\n",
    "\", ft_avg_scores)\n",
    "    ft_results_df.to_markdown(\"./finetuned_model_evaluation02.md\", index=False)\n",
    "    print(\"✅ 파인튜닝 모델 평가 결과가 finetuned_model_evaluation02.md 파일에 저장되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea8b8e8-21d1-46e4-a2be-9084ad8ed6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 40개의 평가 데이터를 로드했습니다.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fedb63be05d41a1a85349fc716fe5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [Base] 모델 답변 생성 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "평가 중 [Base]: 100%|██████████| 40/40 [02:50<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Base] BERTScore 계산 중 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a17877fcd4f415993f300ef4082e2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4104e9dda7004bc6b9a89170111347e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b3204f993f4fe092df7277fd68729a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b75a2184cc646358618103f9b5c646c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe4c7332bb143b3b8e5c3c0ee34ebbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Base] 평가 완료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261122c784804fb395d71b950aecb5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [Finetuned] 모델 답변 생성 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "평가 중 [Finetuned]: 100%|██████████| 40/40 [02:55<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Finetuned] BERTScore 계산 중 ---\n",
      "✅ [Finetuned] 평가 완료\n",
      "\n",
      "--- 전체 평균 점수 ---\n",
      "| Metric | Base Model | Finetuned Model |\n",
      "|---|---|---|| **Precision** | 0.6707 | 0.6806 |\n",
      "| **Recall** | 0.7284 | 0.7343 |\n",
      "| **F1_Score** | 0.6977 | 0.7058 |\n",
      "\n",
      "\n",
      "✅ 비교 평가 결과가 './quantitative_side_by_side_evaluation.md' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "(수정-v3) 정량 평가 스크립트.\n",
    "\n",
    "변경 사항:\n",
    "- F1-Score 외에 Precision, Recall 점수를 모두 결과에 포함하여 다각적인 분석이 가능하도록 함.\n",
    "- 최종 보고서에 세 가지 지표(P, R, F1)를 모두 나란히 비교하여 모델의 성향을 파악하기 용이하게 함.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import bert_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 공통 설정 ---\n",
    "BASE_MODEL_PATH = \"./exaone_4.0_1.2b\"\n",
    "ADAPTER_PATH = \"./llm_finetuned_model\"\n",
    "TEST_DATA_PATH = './test.jsonl'\n",
    "OUTPUT_MD_PATH = \"./quantitative_side_by_side_evaluation.md\"\n",
    "\n",
    "def evaluate_model(model_name, model, tokenizer, data):\n",
    "    \"\"\"주어진 모델에 대해 평가를 수행하고 결과 데이터프레임을 반환하는 함수\"\"\"\n",
    "    print(f\"\\n--- [{model_name}] 모델 답변 생성 시작 ---\")\n",
    "    \n",
    "    predictions, references, questions = [], [], []\n",
    "\n",
    "    for item in tqdm(data, desc=f\"평가 중 [{model_name}]\"):\n",
    "        question = item['messages'][0]['content']\n",
    "        reference_answer = item['messages'][1]['content']\n",
    "        \n",
    "        messages = [{\"role\": \"user\", \"content\": question}]\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        \n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "        \n",
    "        output = model.generate(\n",
    "            input_ids, max_new_tokens=256, do_sample=False, eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        full_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        answer = full_text.split(\"assistant\\n\")[1].strip() if \"assistant\\n\" in full_text else full_text\n",
    "\n",
    "        predictions.append(answer)\n",
    "        references.append(reference_answer)\n",
    "        questions.append(question)\n",
    "\n",
    "    print(f\"--- [{model_name}] BERTScore 계산 중 ---\")\n",
    "    bert_p, bert_r, bert_f1 = bert_score.score(\n",
    "        predictions, references, lang=\"ko\", model_type=\"bert-base-multilingual-cased\", verbose=False\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"Question\": questions,\n",
    "        f\"{model_name}_Answer\": predictions,\n",
    "        f\"{model_name}_Precision\": bert_p.tolist(),\n",
    "        f\"{model_name}_Recall\": bert_r.tolist(),\n",
    "        f\"{model_name}_F1_Score\": bert_f1.tolist(),\n",
    "        \"Reference Answer\": references\n",
    "    })\n",
    "    print(f\"✅ [{model_name}] 평가 완료\")\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    with open(TEST_DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "        test_data = [json.loads(line) for line in f if line.strip()]\n",
    "    print(f\"✅ 총 {len(test_data)}개의 평가 데이터를 로드했습니다.\")\n",
    "\n",
    "    # --- 모델 평가 ---\n",
    "    base_model, tokenizer = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True, device_map=\"auto\", torch_dtype=torch.bfloat16), AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "    base_results_df = evaluate_model(\"Base\", base_model, tokenizer, test_data)\n",
    "    del base_model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    base_model_for_peft = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "    finetuned_model = PeftModel.from_pretrained(base_model_for_peft, ADAPTER_PATH).merge_and_unload()\n",
    "    ft_results_df = evaluate_model(\"Finetuned\", finetuned_model, tokenizer, test_data)\n",
    "    del base_model_for_peft, finetuned_model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # --- 결과 병합 및 저장 ---\n",
    "    comparison_df = pd.merge(base_results_df, ft_results_df, on=[\"Question\", \"Reference Answer\"])\n",
    "    \n",
    "    # 컬럼 순서 재정렬\n",
    "    comparison_df = comparison_df[[\n",
    "        \"Question\", \"Reference Answer\", \n",
    "        \"Base_Answer\", \"Base_Precision\", \"Base_Recall\", \"Base_F1_Score\",\n",
    "        \"Finetuned_Answer\", \"Finetuned_Precision\", \"Finetuned_Recall\", \"Finetuned_F1_Score\"\n",
    "    ]]\n",
    "\n",
    "    # 전체 평균 점수 계산\n",
    "    avg_scores_text = \"| Metric | Base Model | Finetuned Model |\\n\"\n",
    "    avg_scores_text += \"|---|---|---|\"\n",
    "    for metric in [\"Precision\", \"Recall\", \"F1_Score\"]:\n",
    "        base_avg = comparison_df[f'Base_{metric}'].mean()\n",
    "        ft_avg = comparison_df[f'Finetuned_{metric}'].mean()\n",
    "        avg_scores_text += f\"| **{metric}** | {base_avg:.4f} | {ft_avg:.4f} |\\n\"\n",
    "\n",
    "    print(\"\\n--- 전체 평균 점수 ---\")\n",
    "    print(avg_scores_text)\n",
    "\n",
    "    # Markdown 파일로 저장\n",
    "    with open(OUTPUT_MD_PATH, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# 정량 평가 비교 (P, R, F1) (v2)\\n\\n\")\n",
    "        f.write(\"## 전체 평균 점수\\n\\n\")\n",
    "        f.write(avg_scores_text)\n",
    "        f.write(\"\\n\\n## 개별 결과 비교\\n\\n\")\n",
    "        f.write(comparison_df.to_markdown(index=False))\n",
    "\n",
    "    print(f\"\\n✅ 비교 평가 결과가 '{OUTPUT_MD_PATH}' 파일에 저장되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
